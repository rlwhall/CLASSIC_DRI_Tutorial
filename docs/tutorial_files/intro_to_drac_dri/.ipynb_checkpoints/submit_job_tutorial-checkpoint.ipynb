{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d07642",
   "metadata": {},
   "source": [
    "# Facilitator Speaking Notes\n",
    "\n",
    "### Overview for Facilitator\n",
    "Speaking notes for an Introduction to Alliance Digital Research Infrastructure (DRI) with workshop participants. Learners should already be familiar with the concept of a terminal, and the basics of DRAC's infrastructure. This session will introduce learners to JupyterHub, submitting a slurm job, and running the CLASSIC model.\n",
    "\n",
    "Instructions for the facilitator are italicized. Code sections indicate commands that the facilitator should enter and execute in their own terminal.\n",
    "\n",
    "**Note:** This tutorial was designed for use on a Magic Castle virtual cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5117d7",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "*Pass out a username and password to each workshop participant, they will need it to log onto the Magic Castle JupyterHub*\n",
    "\n",
    "We are going to connect to a DRAC's cluster using JupyterHub. JupyterHub is a development environment which will give us a more user-friendly interface than just the terminal for interacting with the cluster.\n",
    "\n",
    "*Write the JupyterHub URL on the board and get students to navigate to it*\n",
    "\n",
    "*Follow along with the instructions below to demonstrate what to do*\n",
    "<br>You should be directed to a login page. Use the Username and Password provided to sign in. You can leave the \"OTP\" field blank.\n",
    "\n",
    "You will be redirected to a \"Server Options\" page. Update the following fields:\n",
    "- **Time (hours)**: 3\n",
    "- **Memory**: 1500 \n",
    "\n",
    "Then click the \"Start\" button.\n",
    "\n",
    "You will see a message that your server is starting up. It may take a minute for the server to launch. \n",
    "\n",
    "*Give students a quick tour of the JupyterHub interface*\n",
    "\n",
    "*Get everyone to open a terminal*\n",
    "*Get them to do basic `ls`, `pwd`, `cd` commands to familiarize themselves, and point out how they can navigate around to different files using the JupterHub file navigation bar on the left-hand side of the screen.*\n",
    "\n",
    "*There will be a shared common directory which everyone can see and access, and then each user will have their own personal directory. Make sure everyone navigates to their user's home directory*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95afa122",
   "metadata": {},
   "source": [
    "*Point out CLASSIC files, and show them around*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4c00e",
   "metadata": {},
   "source": [
    "### Environment Configuration\n",
    "\n",
    "We need to configure our environment by loading a few packages into JupyterLab.\n",
    "\n",
    "I like to think of packages as tools that I can add into my toolbox. Each package is a big or small tool that lets me accomplish a task a lot more efficiently than if I didn't have it. \n",
    "\n",
    "Navigate to the \"Softwares\" menu on the sidebar, and search for \"scipy-stack/2023b\" and Load it.\n",
    "<br>Do the same for \"mpi4py/3.1.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24947cc8",
   "metadata": {},
   "source": [
    "#### Install requirements\n",
    "\n",
    "There are a few packages we need to install on the machine. They are found in the `requirements.txt` file\n",
    "\n",
    "*Optional: Open requirements.txt and get students to see what is in there*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51967530",
   "metadata": {},
   "source": [
    "In the terminal, navigate to the `ARC_for_EESC` folder. Use the `pwd` command to get the file path for that folder.\n",
    "\n",
    "In the terminal enter\n",
    "`pip install -r ` then paste the file path you just copied, and finally add `/requirements.txt` behind it. \n",
    "\n",
    "The final command should look like `pip install -r /home/USER_NAME/projects/def-sponsor00/ARC_for_EESC/requirements.txt`\n",
    "Substitute `USER_NAME` with your user name.\n",
    "ex. `pip install -r /home/user01/projects/def-sponsor00/ARC_for_EESC/requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9ba47-780b-45eb-a406-f56a7d52d35e",
   "metadata": {},
   "source": [
    "### File and Folder Organization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed1b482c-c1e6-4730-b37e-1ec871dd5c1e",
   "metadata": {},
   "source": [
    "#### Copy job and job options file\n",
    "\n",
    "Using the side panel, navigate to the `ARC_for_EESC` folder. We're going to copy two files from this folder to our personal folders.\n",
    "- `classic_submit_dra.sh`\n",
    "- `job_options.txt`\n",
    "\n",
    "We are creating copies of these files in our personal folders so that we aren't all trying to open and edit the same document at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68c9eb",
   "metadata": {},
   "source": [
    "#### Create a folder for CLASSIC outputs\n",
    "\n",
    "We also need to create a folder where CLASSIC can store the outputs from the model. \n",
    "\n",
    "Navigate to `/home/USER_NAME/project/def-sponsor00/USER_NAME`\n",
    "<br>ex. `/home/user01/project/def-sponsor00/user01`\n",
    "\n",
    "Now, create a folder here and call it `netcdf_files`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b9f71",
   "metadata": {},
   "source": [
    "### Submitting a job\n",
    "\n",
    "Next, we're going to send a job request to the server to run the CLASSIC model.\n",
    "\n",
    "We need to submit our job request to DRAC's scheduling software, called slurm. DRAC needs a scheduling software because it can have a high demand for its computing resources, but only finite resources available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd026b4",
   "metadata": {},
   "source": [
    "Before we submit our job, let's take a look at what we're asking the computer to run. \n",
    "\n",
    "*Navigate to the `classic_submit_dra.sh` script*\n",
    "\n",
    "The job we're going to submit runs the following bash script. The computer will read and execute each line one by one from top to bottom. \n",
    "\n",
    "Let's go through it together. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33d0de",
   "metadata": {},
   "source": [
    "`#!/bin/sh`\n",
    "This tells our computer to open a shell where bash commands will be entered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3ca68",
   "metadata": {},
   "source": [
    "```\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=4\n",
    "#SBATCH --time=00:30:00\n",
    "#SBATCH --mem=2G\n",
    "```\n",
    "These are a series of commands for the slurm scheduling software, informing it of the resources that our job will require which will help it schedule the job. \n",
    "\n",
    "When thinking about scheduling, I like to envision a laundromat.  \n",
    "\n",
    "<img src=\"images/laundry.png\" alt=\"Laundromat\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4a8df",
   "metadata": {},
   "source": [
    "Remember how a cluster is made up of multiple computers? Each computer is called a node. \n",
    "So in our laundromat analogy, a node is a single laundromat, and a cluster is a whole city block filled with laundromat after laundromat.\n",
    "\n",
    "With \n",
    "`#SBATCH --nodes=1`\n",
    "We're telling slurm that we only need to use one node. In our laundromat analogy, we're going to a single laundromat.\n",
    "\n",
    "Within each node, there are multiple processors that do the actual computations. These are known as cores or CPUs. In our laundromat each node is an individual washing machine.\n",
    "\n",
    "With \n",
    "`SBATCH --ntasks-per-node=2`\n",
    "We're telling slurm that we need to use 2 cores.\n",
    "\n",
    "To allocate its resources efficiently, slurm needs to know how long you expect your job to run for. Like the timer on a washing machine.\n",
    "\n",
    "With\n",
    "`SBATCH --time=00:30:00`\n",
    "We're telling slurm we need 30 minutes to complete our job. The timer uses the format HH:MM:SS.\n",
    "\n",
    "Finally, slurm needs to know how much memory the job will require. This is the amount of working memory, or RAM, that it takes up on the node. You can think of this as the node's short-term memory. When thinking of our laundromat, the RAM is the actual physical space available inside the machines. \n",
    "\n",
    "With \n",
    "`SBATCH --men=2G`\n",
    "We're telling slurm we need 2 GB of memory for our job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52e00a",
   "metadata": {},
   "source": [
    "##### Small activity\n",
    "\n",
    "I want you all to think about the following scenario. It's a Thursday night, and your parents are arriving tomorrow for a visit where they'll stay with you. You're frantically cleaning your house, and decide to wash your laundry, towels, and bedsheets at the laundromat down the road. At the last minute, your roommate asks you to wash their laundry and sheets too, seeing as \"you're already going to the laundromat anyway\". \n",
    "\n",
    "You only have 2 hours until you want to go to sleep, but you have 5 loads of laundry! What do you do?\n",
    "\n",
    "*Coach folks into realizing that the most efficient solution is to run 5 loads of laundry in five different machines*\n",
    "\n",
    "Great, so by diving our job into smaller loads and assigning each load to it's own machine, we were able to complete our job faster. \n",
    "\n",
    "In this scenario what does this represent doing with DRI?\n",
    "\n",
    "*Answer: parallel processing, although they don't know the term for that yet*\n",
    "\n",
    "Thinking about CLASSIC, when we run a simulation over a large area, parallel processing makes this process much more efficient. Based on what you've learned about CLASSIC so far, what's one aspect of the model structure that lends it to parallel processing?\n",
    "\n",
    "*Hint: Try to think about how the model can be broken into smaller pieces*\n",
    "*Answer: The gridded structure allows each grid cell to be handled individually*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71045570",
   "metadata": {},
   "source": [
    "##### Back to job script\n",
    "\n",
    "Okay, moving back to our job script, the next part of the code is\n",
    "```\n",
    "module load gcc\n",
    "module load openmpi\n",
    "module load cdo\n",
    "module load nco\n",
    "module load netcdf-fortran-mpi\n",
    "module load hdf5-mpi\n",
    "```\n",
    "\n",
    "This is a loading a series of packages that CLASSIC will need to run.\n",
    "\n",
    "Lastly we have the line\n",
    "`/project/def-sponsor00/ARC_for_EESC/CLASSIC/bin/CLASSIC_parallel /project/def-sponsor00/ARC_for_EESC/job_options.txt -82.156/48.217`\n",
    "which will execute CLASSIC.\n",
    "\n",
    "This has three parts.\n",
    " 1. `/project/def-sponsor00/ARC_for_EESC/CLASSIC/bin/CLASSIC_parallel`\n",
    "    - This tells the computer which file we're running. \n",
    " 3. `/project/def-sponsor00/ARC_for_EESC/job_options.txt`\n",
    "    - This is a settings file that `CLASSIC_parallel` needs to run. For example, where CLASSIC can find the input data it needs to make it's predictions.\n",
    " 5. `-82.156/48.217`\n",
    "    - This is the geographic range of the area to model with CLASSIC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b885b15",
   "metadata": {},
   "source": [
    "#### Update job_options.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0794e39",
   "metadata": {},
   "source": [
    "*Get participants to navigate to the `job_options.txt` file in their **personal** folder and open it*\n",
    "\n",
    "On line 213, update the line of code to use your user name.\n",
    "<br>`output_directory = '/project/def-sponsor00/USER_NAME/netcdf_files' ,   ` \n",
    "<br>ex. `output_directory = '/project/def-sponsor00/user01/netcdf_files' ,   `\n",
    "\n",
    "This will make sure the CLASSIC outputs from your CLASSIC job are saved in the `netcdf_files` folder in your personal directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53dc3f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Submit slurm job\n",
    "\n",
    "We're ready to submit our job using slurm. \n",
    "\n",
    "Open a terminal window, and use your `cd` command to navigate to your personal user folder. \n",
    "\n",
    "Get the path of the script file using the `pwd` command. \n",
    "ex. `/home/user01/project/def-sponsor00/user01/classic_submit_dra.sh`\n",
    "\n",
    "Next, in ther terminal, enter `sbatch` followed by the path of the script file that you just copied. \n",
    "<br>It should look something like this\n",
    "<br>`sbatch /home/user01/project/def-sponsor00/user01/classic_submit_dra.sh`\n",
    "\n",
    "We've now submitted the job to slurm, and it will schedule it to run and execute based on availability on the cluster. \n",
    "\n",
    "We can check on the status of our job using `sq`\n",
    "\n",
    "*Make sure everyone's job is running before sending each person on break*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc86e36",
   "metadata": {},
   "source": [
    "### Break\n",
    "\n",
    "*Break while the model runs (30 minutes)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
