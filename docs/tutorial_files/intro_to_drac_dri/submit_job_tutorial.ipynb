{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57aaa286-941d-4f6e-8257-dbb8afb901e5",
   "metadata": {},
   "source": [
    "# Facilitator Speaking Notes\n",
    "\n",
    "### Overview for Facilitator\n",
    "Speaking notes for an Introduction to Alliance Digital Research Infrastructure (DRI) with workshop participants. Learners should already be familiar with the concept of a terminal, and the basics of DRAC's infrastructure. This session will introduce learners to JupyterHub, submitting a slurm job, and running the CLASSIC model.\n",
    "\n",
    "Instructions for the facilitator are italicized. Code sections indicate commands that the facilitator should enter and execute in their own terminal.\n",
    "\n",
    "**Note:** This tutorial was designed for use on a Magic Castle virtual cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d6864-2161-48c3-b714-dc980a2d33a1",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "*Pass out a username and password to each workshop participant, they will need it to log onto the JupyterHub*\n",
    "\n",
    "We are going to connect to a DRAC's cluster using JupyterHub. JupyterHub is a development environment which will give us a more user friendly interface than the terminal for interacting with the cluser.\n",
    "\n",
    "*Write the JupyterHub URL on the board and get students to navigate to it*\n",
    "\n",
    "*Follow along with the instructions below to demonstrate what to do*\n",
    "<br>You should be directed to a login page. Use the Username and Password provided to sign in. You can leave the \"OTP\" field blank.\n",
    "\n",
    "You will be redirected to a \"Server Options\" page. Update the following fields:\n",
    "- **Time (hours)**: 3\n",
    "- **Memory**: 1500\n",
    "\n",
    "Then click the \"Start\" button.\n",
    "\n",
    "You will see a message that your server is starting up. It may take a minute for the server to launch. \n",
    "\n",
    "*Give students a quick tour of the JupyterHub interface*\n",
    "\n",
    "*Get everyone to open a terminal*\n",
    "*Get them to do basic `ls`, `pwd`, `cd` commands to familarize themselves, and point out how they can navigate around to different files in using the file navigation bar on the left hand side of the screen.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e9df9d-c27b-4102-bfad-367e36403d9c",
   "metadata": {},
   "source": [
    "*Point out CLASSIC files, and show them around*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4dfa07-b636-478a-8e03-202054223998",
   "metadata": {},
   "source": [
    "### Environment Configuration\n",
    "\n",
    "We need to configure our environment by loading a few packages into JupyterLab.\n",
    "\n",
    "I like to think of packages as tools that I can add into my toolbox. Each package is a big or small tool that lets me accomplish a task a lot more efficiently than if I didn't have it. \n",
    "\n",
    "Navigate to the \"Softwares\" menu on the sidebar, and search for \"scipy-stack/2023b\" and Load it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b9c36-86b0-427d-835d-431de07360fa",
   "metadata": {},
   "source": [
    "#### Import xarray\n",
    "\n",
    "There is a package we will need called xarray. We need to install it on the machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91facb-99a4-4b15-b68b-bc09e5d68772",
   "metadata": {},
   "source": [
    "In the terminal enter\n",
    "`pip install xarray --no-index`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa1f54-fda7-47d4-aa2a-d46d54f96b2b",
   "metadata": {},
   "source": [
    "### Submitting a job\n",
    "\n",
    "Next, we're going to send a job request to the server to run the CLASSIC model.\n",
    "\n",
    "We need to submit our job request to DRAC's scheduling software, called slurm. DRAC needs a scheduling software because it can have high demand, but finite resources available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e28bcd-0c16-4c68-a27f-b96868b5822b",
   "metadata": {},
   "source": [
    "Before we submit our job, let's take a looks at what we're asking the computer to run. \n",
    "\n",
    "*Navigate to the `classic_submit_dra.sh` script*\n",
    "\n",
    "The job we're going to submit runs the follow bash script. The computer will read and execute each line one by one from top to bottom. \n",
    "\n",
    "Let's go through it together. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db569bd-d493-465a-8305-1f2f6a3ba6a4",
   "metadata": {},
   "source": [
    "`#!/bin/sh`\n",
    "This tells our computer to open a shell where bash commands will be entered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e35647-9af9-4bc0-aac4-7834d1174643",
   "metadata": {},
   "source": [
    "```\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=4\n",
    "#SBATCH --time=00:30:00\n",
    "#SBATCH --mem=2G\n",
    "```\n",
    "These are a series of commands for the slurm scheduling software, informing it of the resources that our job will require which will help it schedule the job. \n",
    "\n",
    "When thinking about scheduling, I like to envision a landromat.  \n",
    "\n",
    "<img src=\"images/laundry.png\" alt=\"Laundromat\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96041d5-3b15-48e7-9153-dea4050305b5",
   "metadata": {},
   "source": [
    "Remember how a cluster is made up of multiple computers? Each computer is called a node. \n",
    "So in our landromat analogy, a node is a single landromat, and a cluster is a whole city block filled with laundromat after laudromat.\n",
    "\n",
    "With \n",
    "`#SBATCH --nodes=1`\n",
    "We're telling slurm that we only need to use one node.\n",
    "\n",
    "Within each node, there are multiple processors that do the actual computations. These are known as cores or CPUs. In our laundromat each node is an individual washing machine.\n",
    "\n",
    "With \n",
    "`SBATCH --ntasks-per-node=4`\n",
    "We're telling slurm that we need to use 4 cores.\n",
    "\n",
    "To allocate it's resources efficiently, slurm needs to know how long you expect your job to run for. Like the timer on a washing machine.\n",
    "\n",
    "With\n",
    "`SBATCH --time=00:30:00`\n",
    "We're telling slurm we need 30 minutes to comlete our job. The timer uses the format HH:MM:SS.\n",
    "\n",
    "Finally, slurm needs to know how much memory the job will require. This is the amount of working memory, or RAM, that it takes up on the node. You can think of this as the node's short term memory. When thinking of our laundromat, the RAM is the actual physical space available inside the machines. \n",
    "\n",
    "With \n",
    "`SBATCH --men=2G`\n",
    "We're telling slurm we need 2 GB of memory for our job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13586705-e457-49ae-86a5-26d01b90fee2",
   "metadata": {},
   "source": [
    "##### Small activity\n",
    "\n",
    "I want you all to think about the following scenario. It's a Thursday night, and your parents are arriving tomorrow for a visit where they'll stay with you. You're frantically cleaning your house, and decide to wash your laundry, towels, and bedsheets at the laundromat down the road. At the last minute your roommate asks you to wash their laundry and sheets too, seeing as \"you're already going the laundromat\". \n",
    "\n",
    "You only have 3 hours until you want to go to sleep, but you have 5 loads of laundry! What do you do?\n",
    "\n",
    "*Coach folks into realizing that the most efficient solution is to run 5 loads of laundry in five different machines*\n",
    "\n",
    "Great, so by diving our job into smaller loads and assigning each load to it's own machine, we were able to complete our job faster. \n",
    "\n",
    "In this scenario what does this represent doing with DRI?\n",
    "\n",
    "*Answer: parallel processing, although they don't know the term for that yet*\n",
    "\n",
    "Thinking about CLASSIC, when we run a simulation over a large area, parallel processing makes this process much more efficient. Based on what you've learned about CLASSIC so far, what's one aspect of the model structure that lends it to parallel processing?\n",
    "\n",
    "*Hint: Try to think about how the model can be broken into smaller pieces*\n",
    "*Answer: The gridded structure allows each grid cell to be handled individually*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a8f4f-42f4-47c9-8cdb-c7cc35bac560",
   "metadata": {},
   "source": [
    "##### Back to job script\n",
    "\n",
    "Okay, moving back to our job script, the next part of the code is\n",
    "```\n",
    "module load gcc\n",
    "module load openmpi\n",
    "module load cdo\n",
    "module load nco\n",
    "module load netcdf-fortran-mpi\n",
    "module load hdf5-mpi\n",
    "```\n",
    "\n",
    "This is a loading a series of packages that CLASSIC will need to run.\n",
    "\n",
    "Lastly we have the line\n",
    "`CLASSIC/bin/CLASSIC_parallel_intel /home/rlwhall/scratch/test6/job_options.txt 90.5/105.5/30.4/45.5`\n",
    "which will execute CLASSIC.\n",
    "\n",
    "This has three parts.\n",
    " 1. `CLASSIC_2/bin/CLASSIC_parallel_intel`\n",
    "    - This tells the computer which file we're running. \n",
    " 3. `/home/rlwhall/scratch/test6/job_options.txt`\n",
    "    - This is a settings file that `CLASSIC_parallel_intel` needs to run. For example, where CLASSIC can find the input data it needs to make it's predictions.\n",
    " 5. `90.5/105.5/30.4/45.5`\n",
    "    - This is the geographic range of the area to model with CLASSIC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0a192-d104-4eed-944e-c6fe467759e4",
   "metadata": {},
   "source": [
    "##### Submit slurm job\n",
    "\n",
    "We're ready to submit our job using slurm. \n",
    "\n",
    "Open a terminal window, and use your `cd` commands to navigate to the folder which has the `classic_submit_dra.sh` file. \n",
    "\n",
    "Once you're there, enter the following command \n",
    "`sbatch classic_submit_dra.sh`\n",
    "\n",
    "We've now submitted the job to slurm, and it will schedule it to run, and execute it based on availability on the cluster. \n",
    "\n",
    "We can check on the status of our job using\n",
    "`sq`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6d596-f89b-4f04-a4ea-a3dfb43366ae",
   "metadata": {},
   "source": [
    "### Break\n",
    "\n",
    "*Break while the model runs (30 minutes)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901f840-64c8-4463-8632-ab6a666eee02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
